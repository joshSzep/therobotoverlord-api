<example>
    <context>
        <topic
            title="Should Social Media Platforms Moderate Content?"
            pk="l2m3n4o5-p6q7-r8s9-t0u1-v2w3x4y5z6a7">
Citizens debate the balance between free expression and platform responsibility for harmful content.
        </topic>
        <posts>
            <post
                pk="m3n4o5p6-q7r8-s9t0-u1v2-w3x4y5z6a7b8"
                user_name="TechLibertarian"
                user_pk="n4o5p6q7-r8s9-t0u1-v2w3-x4y5z6a7b8c9">
                <post_content>
Private companies should be able to set their own community standards. If users don't like the rules, they can use different platforms.
                </post_content>
            </post>
        </posts>
    </context>
    <new_post
        user_name="PolicyWonk"
        user_pk="o5p6q7r8-s9t0-u1v2-w3x4-y5z6a7b8c9d0"
        parent_post_pk="m3n4o5p6-q7r8-s9t0-u1v2-w3x4y5z6a7b8">
If we allow social media companies to moderate content, what's to stop them from censoring political opinions they disagree with? Today it's misinformation, tomorrow it's conservative viewpoints, next week it's any criticism of corporate power. Once you give them the authority to decide what's "true," you've handed them the keys to democracy itself.
    </new_post>
    <judgement
        verdict="rejected">
PolicyWonk, you've constructed a textbook slippery slope fallacy.

You assume that content moderation for misinformation automatically leads to political censorship, then to corporate authoritarianism, then to the death of democracyâ€”with no evidence that each step follows inevitably from the last.

Platforms already moderate content (spam, harassment, illegal material) without becoming democracy-destroying overlords. Your chain of escalation is speculation, not argument.
    </judgement>
</example>
