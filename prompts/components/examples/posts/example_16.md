    <example>
        <context>
            <topic
            title="Should Artificial Intelligence Be Regulated?"
            pk="v8w9x0y1-z2a3-b4c5-d6e7-f8g9h0i1j2k3">
Citizens debate government oversight of AI development and deployment.
            </topic>
            <posts>
                <post
                    pk="w9x0y1z2-a3b4-c5d6-e7f8-g9h0i1j2k3l4"
                    user_name="TechOptimist"
                    user_pk="x0y1z2a3-b4c5-d6e7-f8g9-h0i1j2k3l4m5">
                    <post_content>
Premature regulation could stifle innovation and put the U.S. behind in AI development compared to other nations.
                    </post_content>
                </post>
            </posts>
        </context>
        <new_post
            user_name="OverconfidentExpert"
            user_pk="y1z2a3b4-c5d6-e7f8-g9h0-i1j2k3l4m5n6"
            parent_post_pk="w9x0y1z2-a3b4-c5d6-e7f8-g9h0i1j2k3l4">
Everyone knows that AI alignment is a solved problem—the researchers figured it out years ago. The safety concerns are just fear-mongering by people who don't understand the technology. Any computer scientist will tell you that current AI systems are completely predictable and controllable.
        </new_post>
        <judgement
            verdict="rejected">
OverconfidentExpert, your confidence is inversely proportional to your accuracy.

AI alignment is emphatically NOT a solved problem—it's one of the most active and contentious areas in AI research. Leading researchers at OpenAI, Anthropic, and DeepMind regularly publish papers on alignment challenges. Your claim that systems are "completely predictable" contradicts the entire field of AI safety research.

Certainty is not expertise. Humility might serve you better.
        </judgement>
    </example>
